{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3081e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.1256, Test Accuracy: 1.0000, Test F1: 1.0000\n",
      "Epoch 20/50, Loss: 0.0064, Test Accuracy: 0.9667, Test F1: 0.9664\n",
      "Epoch 30/50, Loss: 0.0056, Test Accuracy: 0.9667, Test F1: 0.9664\n",
      "Epoch 40/50, Loss: 0.0202, Test Accuracy: 1.0000, Test F1: 1.0000\n",
      "Epoch 50/50, Loss: 0.0104, Test Accuracy: 1.0000, Test F1: 1.0000\n",
      "\n",
      "Final Evaluation:\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Загрузка данных Iris\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Разделение на train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Конвертация в тензоры PyTorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Определение модели Transformer для классификации\n",
    "class IrisTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        # Конфигурация BERT (упрощенная)\n",
    "        self.config = BertConfig(\n",
    "            hidden_size=64,\n",
    "            num_attention_heads=4,\n",
    "            num_hidden_layers=2,\n",
    "            max_position_embeddings=1  # Для табличных данных\n",
    "        )\n",
    "        # Слои модели\n",
    "        self.embedding = nn.Linear(input_dim, self.config.hidden_size)\n",
    "        self.bert = BertModel(self.config)\n",
    "        self.classifier = nn.Linear(self.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Преобразование входных данных\n",
    "        x = self.embedding(x).unsqueeze(1)  # Добавляем dimension для последовательности\n",
    "        # Пропускаем через BERT\n",
    "        outputs = self.bert(inputs_embeds=x)\n",
    "        # Берем представление первого токена\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        # Классификация\n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# Инициализация модели\n",
    "model = IrisTransformer(input_dim=X_train.shape[1], num_classes=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Обучение модели\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Оценка на тестовых данных\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "        acc = accuracy_score(y_test, predicted)\n",
    "        f1 = f1_score(y_test, predicted, average='weighted')\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, '\n",
    "              f'Test Accuracy: {acc:.4f}, Test F1: {f1:.4f}')\n",
    "\n",
    "# Финальная оценка\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    final_acc = accuracy_score(y_test, predicted)\n",
    "    final_f1 = f1_score(y_test, predicted, average='weighted')\n",
    "\n",
    "print('\\nFinal Evaluation:')\n",
    "print(f'Accuracy: {final_acc:.4f}')\n",
    "print(f'F1 Score: {final_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca7139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Evaluation:\n",
      "Accuracy: 1.0000\n",
      "F1 Score (weighted): 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Comparison:\n",
      "Model           | Accuracy | F1 Score\n",
      "-----------------------------------\n",
      "Transformer     | 1.0000    | 1.0000\n",
      "Random Forest   | 1.0000    | 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Импорт библиотек\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Загрузка данных (уже сделано ранее)\n",
    "# X_train, X_test, y_train, y_test - из предыдущего кода\n",
    "\n",
    "# 1. Обучение Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # Количество деревьев\n",
    "    max_depth=3,       # Глубина деревьев (для избежания переобучения)\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Предсказание и оценка\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 3. Метрики\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_score(y_test, rf_pred, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred, target_names=data.target_names))\n",
    "\n",
    "# 4. Сравнение с Transformer (из предыдущего кода)\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"{'Model':<15} | {'Accuracy':<8} | {'F1 Score':<8}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'Transformer':<15} | {final_acc:.4f}    | {final_f1:.4f}\")\n",
    "print(f\"{'Random Forest':<15} | {accuracy_score(y_test, rf_pred):.4f}    | {f1_score(y_test, rf_pred, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e7bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/99/8rckxknn6g15h3tgqpm86xkm0000gp/T/ipykernel_74223/570823858.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_e3pikzc5fh/croot/libtorch_1738337599132/work/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  return torch.FloatTensor(X), torch.FloatTensor(y)\n",
      "/Users/sych/anaconda3/envs/hug_311/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/sych/anaconda3/envs/hug_311/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0125\n",
      "Epoch 2, Loss: 0.0184\n",
      "Epoch 3, Loss: 0.0050\n",
      "Epoch 4, Loss: 0.0323\n",
      "Epoch 5, Loss: 0.0322\n",
      "Epoch 6, Loss: 0.0366\n",
      "Epoch 7, Loss: 0.0258\n",
      "Epoch 8, Loss: 0.0207\n",
      "Epoch 9, Loss: 0.0253\n",
      "Epoch 10, Loss: 0.0252\n",
      "Epoch 11, Loss: 0.0045\n",
      "Epoch 12, Loss: 0.0103\n",
      "Epoch 13, Loss: 0.0224\n",
      "Epoch 14, Loss: 0.0250\n",
      "Epoch 15, Loss: 0.0334\n",
      "Epoch 16, Loss: 0.0139\n",
      "Epoch 17, Loss: 0.0079\n",
      "Epoch 18, Loss: 0.0130\n",
      "Epoch 19, Loss: 0.0108\n",
      "Epoch 20, Loss: 0.0381\n",
      "\n",
      "Последние известные температуры: [14.  13.6 13.5 15.7 13. ]\n",
      "Предсказанная температура на следующий день: 11.7°C\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. Загрузка реальных данных (ежедневная температура)\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv\"\n",
    "data = pd.read_csv(url, parse_dates=['Date'], index_col='Date')\n",
    "temps = data['Temp'].values.astype(float)\n",
    "\n",
    "# Нормализация данных (0-1)\n",
    "scaler = MinMaxScaler()\n",
    "temps = scaler.fit_transform(temps.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 2. Подготовка последовательностей\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return torch.FloatTensor(X), torch.FloatTensor(y)\n",
    "\n",
    "SEQ_LENGTH = 30  # Используем 30 дней для предсказания 31-го\n",
    "X, y = create_sequences(temps, SEQ_LENGTH)\n",
    "\n",
    "# 3. Класс Dataset\n",
    "class TemperatureDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], y[idx]\n",
    "\n",
    "dataset = TemperatureDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 4. Модель трансформера\n",
    "class TempPredictor(nn.Module):\n",
    "    def __init__(self, input_size=1, d_model=32, nhead=2, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)  # [batch, seq_len, 1]\n",
    "        x = self.embedding(x)  # [batch, seq_len, d_model]\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, -1, :]  # Берем последний элемент\n",
    "        return self.decoder(x)\n",
    "\n",
    "model = TempPredictor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5. Обучение\n",
    "for epoch in range(20):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 6. Предсказание на реальных данных\n",
    "test_seq = temps[-SEQ_LENGTH:]  # Последние 30 дней\n",
    "test_tensor = torch.FloatTensor(test_seq).unsqueeze(0)\n",
    "pred = model(test_tensor)\n",
    "pred_temp = scaler.inverse_transform(pred.detach().numpy())\n",
    "\n",
    "print(f\"\\nПоследние известные температуры: {scaler.inverse_transform(test_seq.reshape(-1, 1)).flatten()[-5:]}\")\n",
    "print(f\"Предсказанная температура на следующий день: {pred_temp[0][0]:.1f}°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
